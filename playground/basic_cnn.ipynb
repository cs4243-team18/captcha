{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from helper_functions.encode import (\n",
    "    prepare_training_data, CHARACTERS, \n",
    "    segment_captcha_with_projection, preprocess_image,\n",
    "    PROJECTION_THRESHOLD, IMG_HEIGHT, IMG_WIDTH\n",
    ")\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Custom Dataset Class\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, X_img, y):\n",
    "        self.X = torch.tensor(X_img, dtype=torch.float32).permute(0, 3, 1, 2)  # NHWC -> NCHW\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# CNN Model Architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 10 * 7, 128)  # Adjusted for 40x30 input\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 10 * 7)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Character-Level Evaluation Function\n",
    "def evaluate_character_level(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'precision': precision_score(all_labels, all_preds, average='macro', zero_division=0),\n",
    "        'recall': recall_score(all_labels, all_preds, average='macro', zero_division=0),\n",
    "        'f1': f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    }\n",
    "\n",
    "# Captcha-Level Evaluation Function\n",
    "def evaluate_captcha_level(model, folder_path, device):\n",
    "    model.eval()\n",
    "    all_images = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Initialize metrics\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for filename in tqdm(all_images, desc=\"Evaluating CAPTCHAs\"):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        correct_label = os.path.splitext(filename)[0].split('-')[0]\n",
    "        \n",
    "        # Preprocess and segment\n",
    "        image = cv2.imread(image_path)\n",
    "        thresh = preprocess_image(image)\n",
    "        boundaries, _, _ = segment_captcha_with_projection(thresh, PROJECTION_THRESHOLD)\n",
    "        \n",
    "        # Skip if segmentation failed\n",
    "        if len(boundaries) != len(correct_label):\n",
    "            continue\n",
    "        \n",
    "        # Process each character\n",
    "        predicted_chars = []\n",
    "        for i, (start, end) in enumerate(boundaries):\n",
    "            char_img = thresh[:, start:end]\n",
    "            resized = cv2.resize(char_img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "            resized = resized.reshape(IMG_HEIGHT, IMG_WIDTH, 1) / 255.0\n",
    "            \n",
    "            # Convert to tensor and predict\n",
    "            tensor_img = torch.tensor(resized, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(tensor_img)\n",
    "                _, pred = torch.max(outputs, 1)\n",
    "                predicted_char = CHARACTERS[pred.item()]\n",
    "                predicted_chars.append(predicted_char)\n",
    "                \n",
    "                # Collect true and predicted labels\n",
    "                y_true.append(correct_label[i])\n",
    "                y_pred.append(predicted_char)\n",
    "        \n",
    "        # Update CAPTCHA-level accuracy\n",
    "        if ''.join(predicted_chars) == correct_label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    if total == 0:\n",
    "        return {\n",
    "            'accuracy': 0.0,\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0\n",
    "        }\n",
    "    \n",
    "    # Calculate character-level metrics\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(y_true, y_pred, labels=list(CHARACTERS), average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, labels=list(CHARACTERS), average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, labels=list(CHARACTERS), average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing Data: 100%|██████████| 7437/7437 [00:48<00:00, 154.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing Data: 100%|██████████| 1894/1894 [00:12<00:00, 154.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1 Loss: 1.5586\n",
      "Epoch 2 Loss: 0.8260\n",
      "Epoch 3 Loss: 0.6574\n",
      "Epoch 4 Loss: 0.5540\n",
      "Epoch 5 Loss: 0.4813\n",
      "Epoch 6 Loss: 0.4177\n",
      "Epoch 7 Loss: 0.3691\n",
      "Epoch 8 Loss: 0.3277\n",
      "Epoch 9 Loss: 0.2941\n",
      "Epoch 10 Loss: 0.2578\n",
      "Epoch 11 Loss: 0.2293\n",
      "Epoch 12 Loss: 0.2052\n",
      "Epoch 13 Loss: 0.1837\n",
      "Epoch 14 Loss: 0.1669\n",
      "Epoch 15 Loss: 0.1482\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "train_folder = \"../data/train/combine\"\n",
    "test_folder = \"../data/test/combine\"\n",
    "\n",
    "print(\"Preparing training data...\")\n",
    "X_train, _, y_train_onehot, _, _ = prepare_training_data(train_folder)\n",
    "y_train = torch.tensor(np.argmax(y_train_onehot, axis=1), dtype=torch.long)\n",
    "\n",
    "print(\"Preparing test data...\")\n",
    "X_test, _, y_test_onehot, _, _ = prepare_training_data(test_folder)\n",
    "y_test = torch.tensor(np.argmax(y_test_onehot, axis=1), dtype=torch.long)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(CharDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(CharDataset(X_test, y_test), batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN(num_classes=len(CHARACTERS)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "print(\"Training model...\")\n",
    "for epoch in range(15):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} Loss: {running_loss/len(train_loader.dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Character-Level Evaluation:\n",
      "Accuracy: 0.8188\n",
      "Precision: 0.8243\n",
      "Recall: 0.8163\n",
      "F1: 0.8173\n",
      "\n",
      "Captcha-Level Evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating CAPTCHAs: 100%|██████████| 1894/1894 [00:20<00:00, 94.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4384\n",
      "Precision: 0.8243\n",
      "Recall: 0.8163\n",
      "F1: 0.8173\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluation\n",
    "print(\"\\nCharacter-Level Evaluation:\")\n",
    "char_metrics = evaluate_character_level(model, test_loader, device)\n",
    "for metric, value in char_metrics.items():\n",
    "    print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nCaptcha-Level Evaluation:\")\n",
    "captcha_metrics = evaluate_captcha_level(model, test_folder, device)\n",
    "for metric, value in captcha_metrics.items():\n",
    "    print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
